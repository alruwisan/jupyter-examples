{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abc1d809-dc1e-4472-ae00-7a134feee2b0",
   "metadata": {},
   "source": [
    "# Pegasus Fabric Setup\n",
    "\n",
    "This notebook deploys a distributed **Pegasus/HTCondor** infrastructure on the FABRIC testbed for running scientific workflows.\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "- **Submit Node**: Central Manager running HTCondor scheduler and Pegasus WMS\n",
    "- **Worker Nodes**: Distributed execution points across FABRIC sites connected via FABNetv4\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. Create FABRIC slice with submit and worker nodes\n",
    "2. Configure FABNetv4 networking between all nodes\n",
    "3. Install HTCondor and Pegasus on all nodes\n",
    "4. Configure SSH key exchange for passwordless access\n",
    "5. Set up `/etc/hosts` for hostname resolution\n",
    "6. Configure HTCondor roles (Central Manager + Execute nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f6d53c-4d4a-4692-ab4b-bcee89c571b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import traceback\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import tz\n",
    "from ipaddress import ip_network, ip_address, IPv4Address, IPv6Address, IPv4Network, IPv6Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2563fb51-b0a2-402b-810a-b1e54fca1516",
   "metadata": {},
   "source": [
    "## Fabric Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f2cd4d-c85b-4517-9f36-af0d3fb9a3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "fablib = fablib_manager()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60451416-b93c-4368-ab0b-03004d3ce9bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fabric Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b11ad9-64af-439a-be8f-351cc18d4f00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a FABlib manager\n",
    "#site_names = ['INDI', 'LOSA', 'UCSD', 'GATECH', 'PSC', 'STAR', 'SALT', 'UTAH', 'MICH', 'FIU', 'GPN', 'WASH', 'RUTG', 'DALL', 'CLEM', 'AMST']\n",
    "#site_names = ['UCSD', 'CLEM']\n",
    "site_names = fablib.get_random_sites(2)\n",
    "\n",
    "# FABRIC Config\n",
    "fabric_prefix =  f\"pegasus-\"\n",
    "fabric_slice_name = fabric_prefix+'experiment'\n",
    "fabric_os_image='default_ubuntu_24'\n",
    "\n",
    "fabric_submit_name = fabric_prefix+'submit'\n",
    "#fabric_submit_site = 'LOSA'\n",
    "fabric_submit_site = fablib.get_random_site()\n",
    "fabric_submit_cores = 16\n",
    "fabric_submit_ram = 32\n",
    "fabric_submit_disk = 500\n",
    "\n",
    "worker_nodes = []\n",
    "for n in site_names:\n",
    "    for i in range(1,2):\n",
    "        worker_nodes.append({\n",
    "            \"name\": f\"{n}-worker-{i}\",\n",
    "            \"site\": n,\n",
    "            \"cores\": 24,\n",
    "            \"ram\": 48,\n",
    "            \"disk\": 500,\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a83d22f-7561-4ff0-aa92-9e1cb670f5ba",
   "metadata": {},
   "source": [
    "## Create Fabric Slice\n",
    "This cell creates a new FABRIC slice, adds a submit node and multiple worker nodes (one per site), attaches each node to FABNet, and submits the slice request. If an error occurs, it prints the exception and traceback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5075a988-c0a9-4ef3-b782-5a377caa8f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #Create Slice\n",
    "    fabric_slice = fablib.new_slice(name=fabric_slice_name)\n",
    "    \n",
    "    # Add federated learning submit node\n",
    "    fabric_submit = fabric_slice.add_node(\n",
    "                        name=fabric_submit_name, \n",
    "                        site=fabric_submit_site,\n",
    "                        image=fabric_os_image,\n",
    "                        cores=fabric_submit_cores,\n",
    "                        ram=fabric_submit_ram,\n",
    "                        disk=fabric_submit_disk)\n",
    "    fabric_submit.add_fabnet()\n",
    "\n",
    "    for w in worker_nodes:\n",
    "        worker_node = fabric_slice.add_node(\n",
    "                        name=w[\"name\"], \n",
    "                        site=w[\"site\"],\n",
    "                        image=fabric_os_image,\n",
    "                        cores=w[\"cores\"],\n",
    "                        ram=w[\"ram\"],\n",
    "                        disk=w[\"disk\"])\n",
    "        worker_node.add_fabnet()\n",
    "\n",
    "    #Submit the Request\n",
    "    fabric_slice.submit()\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {e}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mg7oasqq1gj",
   "metadata": {},
   "source": [
    "## Cache Slice Objects\n",
    "\n",
    "Retrieve the slice and cache nodes, networks, and interfaces to avoid expensive SSH operations during iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89659c5-d5c2-48e7-837e-02280de0d0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(fabric_slice_name)\n",
    "\n",
    "# Cache the nodes, networks, interfaces; this becomes expensive as the slice scales due to fablib's limitation of doing SSH for interfaces\n",
    "nodes = slice.get_nodes()\n",
    "node_by_name = {n.get_name(): n for n in nodes}\n",
    "\n",
    "networks = slice.get_networks()\n",
    "nw_by_name = {nw.get_name(): nw for nw in networks}\n",
    "\n",
    "# Cache interfaces (expensive) once\n",
    "node_ifaces = {n.get_name(): n.get_interfaces() for n in nodes}\n",
    "nw_ifaces = {nw.get_name(): nw.get_interfaces() for nw in networks}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vx7gkslcfrg",
   "metadata": {},
   "source": [
    "## Fix Hostname Resolution\n",
    "\n",
    "Comment out the default `127.0.1.1` hostname entry to prevent HTCondor from binding to localhost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f2b93f-7e74-4999-90c0-bb71e8f71467",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in nodes:\n",
    "    n.execute(r\"sudo sed -i 's/^127\\.0\\.1\\.1 /#127.0.1.1 /' /etc/hosts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472zqx0xuw6",
   "metadata": {},
   "source": [
    "## Upload Node Tools\n",
    "\n",
    "Upload configuration scripts to all nodes for HTCondor and Pegasus setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a439b5b-a604-43aa-a743-cb62dce86d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in nodes:\n",
    "    n.upload_directory(\"node_tools\", \".\")\n",
    "    n.execute(\"cd node_tools && chmod +x *.sh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ju91jlf42z",
   "metadata": {},
   "source": [
    "## Install HTCondor and Pegasus\n",
    "\n",
    "Install HTCondor distributed workload management system and Pegasus workflow management system on all nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550ad00f-f63c-4de6-bf88-afec8c2db7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in nodes:\n",
    "    node.execute(\"cd node_tools && ./htcondor.sh --no-dry-run\", quiet=True, output_file=f\"{node.get_name()}.log\")\n",
    "    node.execute(\"cd node_tools && ./pegasus.sh --no-dry-run\", quiet=True, output_file=f\"{node.get_name()}.log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lf9at8jjv4o",
   "metadata": {},
   "source": [
    "## Configure SSH Key Exchange\n",
    "\n",
    "Set up passwordless SSH access between all nodes for both root and ubuntu users.\n",
    "\n",
    "### Generate and Exchange Root SSH Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e6c24-b426-4e81-8f18-410712b8dfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in nodes:\n",
    "    node.execute('sudo ssh-keygen -t rsa -N \"\" -f /root/.ssh/id_rsa', quiet=True, output_file=f\"{node.get_name()}.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b2d507-6850-463a-9048-bf793ed54388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from ipaddress import IPv4Network\n",
    "\n",
    "# ------------------------------------\n",
    "# 1) Collect SSH pubkeys in parallel\n",
    "# ------------------------------------\n",
    "def read_pubkey(node):\n",
    "    out, err = node.execute(\"sudo cat /root/.ssh/id_rsa.pub\", quiet=True)\n",
    "    return node.get_name(), out.strip()\n",
    "\n",
    "key_map = {}\n",
    "with ThreadPoolExecutor(max_workers=min(16, len(nodes) or 1)) as pool:\n",
    "    futures = [pool.submit(read_pubkey, n) for n in nodes]\n",
    "    for f in as_completed(futures):\n",
    "        name, key = f.result()\n",
    "        key_map[name] = key\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2) Append other nodes' pubkeys to each authorized_keys\n",
    "#    (parallel + here-doc; idempotent-ish by dedupe)\n",
    "# ---------------------------------------------------\n",
    "def write_keys(node):\n",
    "    my_name = node.get_name()\n",
    "    ssh_keys_block = \"\\n\".join(\n",
    "        k for nn, k in key_map.items() if nn != my_name and k\n",
    "    ).strip()\n",
    "    if not ssh_keys_block:\n",
    "        return\n",
    "\n",
    "    # Ensure .ssh exists and permissions are correct, then append unique keys\n",
    "    # Use sort -u to avoid duplicate lines across reruns.\n",
    "    script = r\"\"\"sudo bash -lc '\n",
    "set -e\n",
    "mkdir -p /root/.ssh\n",
    "touch /root/.ssh/authorized_keys\n",
    "cat <<\"EOF\" >> /root/.ssh/authorized_keys.__tmp\n",
    "{keys}\n",
    "EOF\n",
    "cat /root/.ssh/authorized_keys /root/.ssh/authorized_keys.__tmp | sort -u > /root/.ssh/authorized_keys.__new\n",
    "mv /root/.ssh/authorized_keys.__new /root/.ssh/authorized_keys\n",
    "rm -f /root/.ssh/authorized_keys.__tmp\n",
    "chmod 700 /root/.ssh\n",
    "chmod 600 /root/.ssh/authorized_keys\n",
    "'\"\"\".format(keys=ssh_keys_block)\n",
    "    node.execute(script, quiet=True)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=min(16, len(nodes) or 1)) as pool:\n",
    "    futures = [pool.submit(write_keys, n) for n in nodes]\n",
    "    for _ in as_completed(futures):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e4t6jfieg",
   "metadata": {},
   "source": [
    "### Generate and Exchange Ubuntu User SSH Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c4d1e9-79d4-4977-a512-e84815356750",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in nodes:\n",
    "    node.execute('ssh-keygen -t rsa -N \"\" -f /home/ubuntu/.ssh/id_rsa', quiet=True, output_file=f\"{node.get_name()}.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2d7218-2b46-4979-bc35-80eb605900da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from ipaddress import IPv4Network\n",
    "\n",
    "# ------------------------------------\n",
    "# 1) Collect SSH pubkeys in parallel\n",
    "# ------------------------------------\n",
    "def read_pubkey(node):\n",
    "    out, err = node.execute(\"cat /home/ubuntu/.ssh/id_rsa.pub\", quiet=True)\n",
    "    return node.get_name(), out.strip()\n",
    "\n",
    "key_map = {}\n",
    "with ThreadPoolExecutor(max_workers=min(16, len(nodes) or 1)) as pool:\n",
    "    futures = [pool.submit(read_pubkey, n) for n in nodes]\n",
    "    for f in as_completed(futures):\n",
    "        name, key = f.result()\n",
    "        key_map[name] = key\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2) Append other nodes' pubkeys to each authorized_keys\n",
    "#    (parallel + here-doc; idempotent-ish by dedupe)\n",
    "# ---------------------------------------------------\n",
    "def write_keys(node):\n",
    "    my_name = node.get_name()\n",
    "    ssh_keys_block = \"\\n\".join(\n",
    "        k for nn, k in key_map.items() if nn != my_name and k\n",
    "    ).strip()\n",
    "    if not ssh_keys_block:\n",
    "        return\n",
    "\n",
    "    # Ensure .ssh exists and permissions are correct, then append unique keys\n",
    "    # Use sort -u to avoid duplicate lines across reruns.\n",
    "    script = r\"\"\"bash -lc '\n",
    "set -e\n",
    "mkdir -p /home/ubuntu/.ssh\n",
    "touch /home/ubuntu/.ssh/authorized_keys\n",
    "cat <<\"EOF\" >> /home/ubuntu/.ssh/authorized_keys.__tmp\n",
    "{keys}\n",
    "EOF\n",
    "cat /home/ubuntu/.ssh/authorized_keys /home/ubuntu/.ssh/authorized_keys.__tmp | sort -u > /home/ubuntu/.ssh/authorized_keys.__new\n",
    "mv /home/ubuntu/.ssh/authorized_keys.__new /home/ubuntu/.ssh/authorized_keys\n",
    "rm -f /home/ubuntu/.ssh/authorized_keys.__tmp\n",
    "chmod 700 /home/ubuntu/.ssh\n",
    "chmod 600 /home/ubuntu/.ssh/authorized_keys\n",
    "'\"\"\".format(keys=ssh_keys_block)\n",
    "    node.execute(script, quiet=True)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=min(16, len(nodes) or 1)) as pool:\n",
    "    futures = [pool.submit(write_keys, n) for n in nodes]\n",
    "    for _ in as_completed(futures):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jj5rnsk9fp",
   "metadata": {},
   "source": [
    "## Setup /etc/hosts\n",
    "\n",
    "Build and deploy `/etc/hosts` entries from the assigned FABNet IP addresses for hostname resolution across all nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f0e329-d30a-4082-b9f7-6b116ec3f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assigned_ip = {}\n",
    "\n",
    "for nw_name, nw in nw_by_name.items():\n",
    "    for iface in nw_ifaces[nw_name]:\n",
    "        node_name = iface.get_node().get_name()\n",
    "        ip = iface.get_ip_addr()\n",
    "        assigned_ip[(nw_name, node_name)] = str(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38268a39-e67f-4049-b164-9968d87f4f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# 3) Build /etc/hosts from the assigned_ip map (no extra get_* calls)\n",
    "#     For each node: add all peers' IPs on the node's networks.\n",
    "# ---------------------------------------------------\n",
    "# Precompute: networks per node from cached node_ifaces\n",
    "from typing import Dict\n",
    "import json\n",
    "\n",
    "# assigned_ip: Dict[Tuple[str, str], str]  # (network, host) -> ip\n",
    "\n",
    "host_to_ip: Dict[str, str] = {}\n",
    "dups: Dict[str, set] = {}\n",
    "\n",
    "for (nw, host), ip in assigned_ip.items():\n",
    "    if host in host_to_ip and host_to_ip[host] != ip:\n",
    "        # If the \"one IP per host\" invariant is broken, record it (we keep the first).\n",
    "        dups.setdefault(host, set()).update({host_to_ip[host], ip})\n",
    "        continue\n",
    "    host_to_ip.setdefault(host, ip)\n",
    "\n",
    "# Optional: if you want to exclude non-agent hosts (keep database, etc.), filter here.\n",
    "# Example to include everything as-is (agents + database):\n",
    "final_pairs = sorted(host_to_ip.items(), key=lambda kv: kv[0])  # sort by hostname\n",
    "\n",
    "block_lines = [f\"{ip} {host}\" for host, ip in final_pairs]\n",
    "hosts_blocks = \"\\n\".join(block_lines)\n",
    "\n",
    "for n in nodes:\n",
    "    stdout, stderr = n.execute(f\"sudo sh -c 'echo \\\"{hosts_blocks}\\\" >> /etc/hosts'\")\n",
    "\n",
    "#-------------------------------\n",
    "# Dump the etc hosts\n",
    "#-------------------------------\n",
    "\n",
    "import json\n",
    "print(\"ETC Hosts:\", json.dumps(hosts_blocks, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2ef7c0-3177-48f9-a6e0-49f1baf7776c",
   "metadata": {},
   "source": [
    "## Configure HTCondor Roles\n",
    "\n",
    "Assign setup scripts based on node role:\n",
    "- **Submit node**: Central Manager configuration (`fabric-submit.sh`)\n",
    "- **Worker nodes**: Execute node configuration (`fabric-worker.sh`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f598d6-0587-48f9-931d-5e9a84552a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in nodes:\n",
    "    if n.get_name() == fabric_submit_name:\n",
    "        n.execute(\"cd node_tools && cp fabric-submit.sh setup.sh\")\n",
    "    else:\n",
    "        n.execute(\"cd node_tools && cp fabric-worker.sh setup.sh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ijb54etg8st",
   "metadata": {},
   "source": [
    "### Run Final Configuration\n",
    "\n",
    "Execute the role-specific setup scripts on all nodes in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86779ee1-7257-41dc-8130-3bfccddbdb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "fabric_submit = node_by_name.get(fabric_submit_name)\n",
    "fabric_submit_addr = fabric_submit.get_interface(network_name=f'FABNET_IPv4_{fabric_submit.get_site()}').get_ip_addr()\n",
    "    \n",
    "#Create execute threads\n",
    "execute_threads = {}\n",
    "for fabric_node in nodes:\n",
    "    os_interface = fabric_node.get_interface(network_name=f'FABNET_IPv4_{fabric_node.get_site()}').get_os_interface()\n",
    "    config_command = f\"sudo bash /home/ubuntu/node_tools/setup.sh {os_interface} {fabric_submit_addr} {fabric_submit_name}\"\n",
    "    print(f\"Starting config on node {fabric_node.get_name()}\")\n",
    "    print(config_command)\n",
    "    execute_threads[fabric_node] = fabric_node.execute_thread(config_command, output_file=f\"{fabric_node.get_name()}.log\")\n",
    "    \n",
    "#Wait for results from threads\n",
    "for fabric_node,thread in execute_threads.items():\n",
    "    print(f\"Waiting for result from node {fabric_node.get_name()}\")\n",
    "    stdout,stderr = thread.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8431158c-4013-4ca7-a390-f05b8d69242f",
   "metadata": {},
   "source": [
    "## Extend Fabric Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da936c18-9212-44b7-aeda-bf2026bd3c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prolong Fabric Slice For 12 Days\n",
    "end_date = (datetime.now(tz=tz.tzutc()) + timedelta(days=14)).strftime(\"%Y-%m-%d %H:%M:%S %z\")\n",
    "try:\n",
    "    fabric_slice = fablib.get_slice(name=fabric_slice_name)\n",
    "    fabric_slice = fabric_slice.renew(end_date)\n",
    "    \n",
    "    fabric_slice = fablib.get_slice(name=fabric_slice_name)\n",
    "    print(f'New lease end time: {fabric_slice.get_lease_end()}')\n",
    "except Exception as e:\n",
    "    print(f\"Fail: {e}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1be68fe-1825-4feb-9e58-da2603bd146b",
   "metadata": {},
   "source": [
    "## Cleanup Fabric (This Deletes The Deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb6751e-d888-46c4-9b00-001bdde7648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fabric_slice = fablib.get_slice(fabric_slice_name)\n",
    "#fabric_slice.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
